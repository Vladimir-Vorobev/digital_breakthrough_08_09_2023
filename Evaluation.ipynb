{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1746bbd4",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e516a76d-32e9-4816-b4f4-f1a499671d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from dateutil import parser\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e99e5",
   "metadata": {},
   "source": [
    "## Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03eb08a3-36ef-4382-b7cd-885f476beb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "gardening_val = pd.read_csv('gardening_test.csv')\n",
    "gardening_train = pd.read_csv('gardening_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dbb3ac",
   "metadata": {},
   "source": [
    "## Функции для работы с датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45027470-63ac-4390-84de-34637b8beb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataset(_train_dataset, _val_dataset, val_data_target, key):\n",
    "    train_dataset, val_dataset = {}, {}\n",
    "    \n",
    "    for receipt_id, item_id in zip(_train_dataset['receipt_id'], _train_dataset[key]):\n",
    "        if receipt_id not in train_dataset:\n",
    "            train_dataset[receipt_id] = []\n",
    "\n",
    "        train_dataset[receipt_id].append(int(item_id))\n",
    "\n",
    "    for receipt_id, item_id in zip(_val_dataset['receipt_id'], _val_dataset[key]):\n",
    "        if receipt_id not in val_dataset:\n",
    "            val_dataset[receipt_id] = []\n",
    "\n",
    "        val_dataset[receipt_id].append(int(item_id))\n",
    "\n",
    "    # for receipt_id in val_dataset:\n",
    "    #     val_dataset[receipt_id].append(int(val_data_target[val_data_target['receipt_id'] == receipt_id][key].tolist()[0]))\n",
    "\n",
    "    val_keys = val_dataset.keys()\n",
    "    train_dataset, val_dataset = list(train_dataset.values()), list(val_dataset.values())\n",
    "\n",
    "    for i in range(len(train_dataset)):\n",
    "        train_dataset[i] = train_dataset[i][-6:]\n",
    "        \n",
    "        for _ in range(6 - len(train_dataset[i])):\n",
    "            train_dataset[i].insert(0, -1)\n",
    "\n",
    "        for j in range(len(train_dataset[i])):\n",
    "            train_dataset[i][j] += 1\n",
    "\n",
    "    for i in range(len(val_dataset)):\n",
    "        val_dataset[i] = val_dataset[i][-6:]\n",
    "        \n",
    "        for _ in range(6 - len(val_dataset[i])):\n",
    "            val_dataset[i].insert(0, -1)\n",
    "\n",
    "        for j in range(len(val_dataset[i])):\n",
    "            val_dataset[i][j] += 1\n",
    "\n",
    "    return train_dataset, val_dataset, val_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9427aa9-a93d-49a4-a6f6-f5c95a1182f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "le1 = preprocessing.LabelEncoder()\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le3 = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bcbdf43-26ef-4169-a24d-8e11faaf9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, val_data, val_data_target):\n",
    "    unique_train_item_ids = dataset['item_id'].unique()\n",
    "    unique_train_good = dataset['good'].unique()\n",
    "    unique_train_brand = dataset['brand'].unique()\n",
    "    \n",
    "    le1.fit(dataset['item_id'])\n",
    "    dataset['item_id'] = le1.transform(dataset['item_id'])\n",
    "\n",
    "    le2.fit(dataset['good'])\n",
    "    dataset['good'] = le2.transform(dataset['good'])\n",
    "\n",
    "    le3.fit(dataset['brand'])\n",
    "    dataset['brand'] = le3.transform(dataset['brand'])\n",
    "    \n",
    "    val_data['item_id'] = [le1.transform([i])[0] if i in unique_train_item_ids else len(unique_train_item_ids) for i in val_data['item_id']]\n",
    "    # val_data_target['item_id'] = [le1.transform([i])[0] if i in unique_train_item_ids else len(unique_train_item_ids) for i in val_data_target['item_id']]\n",
    "    \n",
    "    val_data['good'] = [le2.transform([i])[0] if i in unique_train_good else len(unique_train_good) for i in val_data['good']]\n",
    "    # val_data_target['good'] = [le2.transform([i])[0] if i in unique_train_good else len(unique_train_good) for i in val_data_target['good']]\n",
    "    \n",
    "    val_data['brand'] = [le3.transform([i])[0] if i in unique_train_brand else len(unique_train_brand) for i in val_data['brand']]\n",
    "    # val_data_target['brand'] = [le3.transform([i])[0] if i in unique_train_brand else len(unique_train_brand) for i in val_data_target['brand']]\n",
    "\n",
    "    try:\n",
    "        dataset['item_id'][np.random.choice(list(range(len(dataset))), int(len(val_data['item_id']) * val_data['item_id'].value_counts()[len(unique_train_item_ids)] / len(val_data)))] = len(unique_train_item_ids)\n",
    "    except:\n",
    "        ...\n",
    "    \n",
    "    dataset = dataset.sort_values(by=['local_date'], key=lambda x: x.apply(lambda y: parser.parse(y).timestamp()))\n",
    "    val_data = val_data.sort_values(by=['local_date'], key=lambda x: x.apply(lambda y: parser.parse(y).timestamp()))\n",
    "\n",
    "    train_dataset_item_id, val_dataset_item_id, val_keys = convert_dataset(dataset, val_data, val_data_target, 'item_id')\n",
    "    train_dataset_good, val_dataset_good, _ = convert_dataset(dataset, val_data, val_data_target, 'good')\n",
    "    train_dataset_brand, val_dataset_brand, _ = convert_dataset(dataset, val_data, val_data_target, 'brand')\n",
    "\n",
    "    train_dataset = [[a, b, c] for a, b, c in zip(train_dataset_item_id, train_dataset_good, train_dataset_brand)]\n",
    "    val_dataset = [[a, b, c] for a, b, c in zip(val_dataset_item_id, val_dataset_good, val_dataset_brand)]\n",
    "\n",
    "    return train_dataset, val_dataset, val_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f981768",
   "metadata": {},
   "source": [
    "## Архитектура модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59cb82ba-2bc1-4d50-8c1b-43fc42ef2152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntoken1: int, ntoken2: int, ntoken3: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.pos_encoder1 = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers1 = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder1 = TransformerEncoder(encoder_layers1, nlayers)\n",
    "        self.embedding1 = nn.Embedding(ntoken1, d_model)\n",
    "        self.d_model1 = d_model\n",
    "        self.linear1 = nn.Linear(d_model, ntoken1)\n",
    "\n",
    "        self.pos_encoder2 = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers2 = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder2 = TransformerEncoder(encoder_layers2, nlayers)\n",
    "        self.embedding2 = nn.Embedding(ntoken2, d_model)\n",
    "        self.d_model2 = d_model\n",
    "        self.linear2 = nn.Linear(d_model, ntoken1)\n",
    "\n",
    "        self.pos_encoder3 = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers3 = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder3 = TransformerEncoder(encoder_layers3, nlayers)\n",
    "        self.embedding3 = nn.Embedding(ntoken3, d_model)\n",
    "        self.d_model3 = d_model\n",
    "        self.linear3 = nn.Linear(d_model, ntoken1)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        \n",
    "        self.embedding1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear1.bias.data.zero_()\n",
    "        self.linear1.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "        self.embedding2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear2.bias.data.zero_()\n",
    "        self.linear2.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "        self.embedding3.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear3.bias.data.zero_()\n",
    "        self.linear3.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, good: Tensor, brand: Tensor, mask: Tensor = None) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[seq_len, batch_size]``\n",
    "            good: Tensor, shape ``[seq_len, batch_size]``\n",
    "            brand: Tensor, shape ``[seq_len, batch_size]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        src = self.embedding1(src) * math.sqrt(self.d_model1)\n",
    "        src = self.pos_encoder1(src)\n",
    "        src_output = self.transformer_encoder1(src, mask)\n",
    "        src_output = self.linear1(src_output.mean(0))\n",
    "\n",
    "        good = self.embedding2(good) * math.sqrt(self.d_model2)\n",
    "        good = self.pos_encoder2(good)\n",
    "        good_output = self.transformer_encoder2(good, mask)\n",
    "        good_output = self.linear2(good_output.mean(0))\n",
    "\n",
    "        brand = self.embedding3(brand) * math.sqrt(self.d_model3)\n",
    "        brand = self.pos_encoder3(brand)\n",
    "        brand_output = self.transformer_encoder3(brand, mask)\n",
    "        brand_output = self.linear3(brand_output.mean(0))\n",
    "\n",
    "        output = torch.stack([src_output, good_output, brand_output])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3967075-eccd-4f67-9cec-77e1280c0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e55fc2b9-e1c4-4781-ae63-c9b3717a028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9317c46-ad5c-4bc3-9aa4-55ab57025ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87199/1547639330.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['item_id'][np.random.choice(list(range(len(dataset))), int(len(val_data['item_id']) * val_data['item_id'].value_counts()[len(unique_train_item_ids)] / len(val_data)))] = len(unique_train_item_ids)\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "train_dataset, val_dataset, val_keys = create_dataset(gardening_train, gardening_val, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c05c29",
   "metadata": {},
   "source": [
    "## Инициализация параметров модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc30787a-2955-4f32-9ddd-3371d894ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0fb787",
   "metadata": {},
   "source": [
    "## Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d57b7e8b-93c4-4ea0-b0e9-5d17329a8db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_x = torch.stack([torch.stack([torch.tensor(i[0][:-1]), torch.tensor(i[1][:-1]), torch.tensor(i[2][:-1])]) for i in val_dataset]).transpose(0, 1).transpose(1, 2)\n",
    "output = model(*val_x.to(device))\n",
    "df = pd.DataFrame({'receipt_id': gardening_val['receipt_id'].unique().tolist(), 'item_id': le1.inverse_transform([min(i, 12766) for i in torch.argmax(output[0], dim=1).detach().cpu().tolist()])})\n",
    "df.to_csv(f'submit.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efeedb7-8033-4363-a6f9-633952665acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
